{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 : max score = 241.75\n",
      "Generation 2 : max score = 250.00\n",
      "Generation 3 : max score = 250.00\n",
      "Generation 4 : max score = 250.00\n",
      "Generation 5 : max score = 250.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import gym\n",
    "render = False # to control rendering of the learning process, It will take very long if you render the learning process.\n",
    "episode_len = 200  # length of a single episode\n",
    "number_of_episodes = 10  # evaluate a policy over 10 episodes\n",
    "\n",
    "\n",
    "def run_episode(env, policy):\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    observation = env.reset() \n",
    "    while True:\n",
    "        if render:\n",
    "            env.render()\n",
    "        action = 0 if Multiplyweights(policy, observation) < 0 else 1 # we have a binary set of actions, move left or right.\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        if done:\n",
    "            break\n",
    "    if render:\n",
    "        env.close()\n",
    "    return total_reward\n",
    "\n",
    "\n",
    "def Multiplyweights(policy, observation):\n",
    "    sum=0\n",
    "    for x in range(4):\n",
    "        sum += (policy[x] * observation[x])\n",
    "    return sum\n",
    "\n",
    "\n",
    "def evaluate_policy(env, policy):\n",
    "    total_rewards = 0.0\n",
    "    for _ in range(number_of_episodes):\n",
    "        total_rewards += run_episode(env, policy)\n",
    "    return ((total_rewards/2000)*100)\n",
    "\n",
    "\n",
    "def gen_random_policy():\n",
    "    return np.random.rand(4) * 2 - 1\n",
    "\n",
    "\n",
    "def crossover(policy1, policy2):  # 20% chance of switching each attribute \n",
    "    new_policy = policy1.copy()\n",
    "    for i in range(4):\n",
    "        rand = np.random.uniform()\n",
    "        if rand > 0.79:\n",
    "            new_policy[i] = policy2[i]\n",
    "    return new_policy\n",
    "\n",
    "\n",
    "def mutation(policy):  # less than 10% chance of changing 1 segment\n",
    "    new_policy = policy.copy()\n",
    "    for i in range(4):\n",
    "        rand = np.random.uniform()  # check this\n",
    "        if rand < 0.09:\n",
    "            new_policy[i] = np.random.rand(1) * 2 - 1\n",
    "    return new_policy\n",
    "\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "best_policy = None\n",
    "n_policy = 100  # Number of Policies to start with\n",
    "n_steps = 5  # number of generations we want to go to\n",
    "policy_pop = [gen_random_policy() for _ in range(n_policy)]  # 2d array of our 100 policies\n",
    "policy_scores = []\n",
    "for idx in range(n_steps):\n",
    "    policy_scores = [evaluate_policy(env, p) for p in policy_pop]  # TO store the score of each Policy\n",
    "    print('Generation %d : max score = %0.2f' % (idx + 1, max(policy_scores)))\n",
    "    policy_ranks = list(reversed(np.argsort(policy_scores)))  # List to store the index position of  policies in decending order\n",
    "    elite_set = [policy_pop[x] for x in policy_ranks[:5]]  # TO store the Top 5 policies\n",
    "    select_probs = np.array(policy_scores) / np.sum(policy_scores)  # Dividing each policy score with total policy score\n",
    "    child_set = [crossover(\n",
    "        policy_pop[np.random.choice(range(n_policy), p=select_probs)],\n",
    "        policy_pop[np.random.choice(range(n_policy), p=select_probs)])\n",
    "        for _ in range(n_policy - 5)]\n",
    "    mutated_list = [mutation(p) for p in child_set]  # creating  a mutated list from the policies os the child set\n",
    "    policy_pop = elite_set  # changing our policy set to elite set or say shortening our list to only elite onces\n",
    "    policy_pop += mutated_list\n",
    "    policy_score = [evaluate_policy(env, p) for p in policy_pop]\n",
    "    best_policy = policy_pop[np.argmax(policy_score)]  # select the best policy by index of the max policy score  \n",
    "\n",
    "observation = env.reset()\n",
    "for _ in range(1000): # Testing!!\n",
    "    action = 0 if Multiplyweights(best_policy, observation) < 0 else 1\n",
    "    env.render()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
